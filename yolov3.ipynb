{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGqEz40qLGbTpTfzePOoBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karl-gardner/droplet_detection/blob/master/yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbirS3YgC_dg"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/26833433/99805971-90f66b80-2b3d-11eb-80eb-8b45a15cb68e.jpg\">\n",
        "\n",
        "This is the **official YOLOv3 ðŸš€ notebook** authored by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov3 and https://www.ultralytics.com. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpbVhgNeDDkQ"
      },
      "source": [
        "# 0. Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsvA2iGDDAG5",
        "outputId": "98d6d450-46d0-406e-bab6-be1a131126e0"
      },
      "source": [
        "!git clone https://github.com/karl-gardner/droplet_detection  # clone repo\n",
        "%cd /content/droplet_detection/yolov3\n",
        "!pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from google.colab import files\n",
        "import random\n",
        "import csv\n",
        "\n",
        "%cd /content/droplet_detection\n",
        "import funcs\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZYJ8qng-5mD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beaef669-466d-4fa9-b163-eb43230466d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1wfzT28BOTY"
      },
      "source": [
        "# 1.1 Droplet model dataset from roboflow (PC3DropletDetection2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data With Augmentation for Training (final_dataset)"
      ],
      "metadata": {
        "id": "A9EADxkkrlZv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAPACwmBOcm"
      },
      "source": [
        "%cd /content/droplet_detection\n",
        "!curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data with No Augmentation (No_Augmentation)"
      ],
      "metadata": {
        "id": "-H3SDWiPrqo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "8mv-LJfSrvQ9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRC1AAs0BT97"
      },
      "source": [
        "# 1.2 Cell model dataset from roboflow (Cropped_Drops2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data With Augmentation for Training (final_dataset)"
      ],
      "metadata": {
        "id": "JMeQTNmRKkB_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCFocYgtBUKA"
      },
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data with No Augmentation (No_Augmentation)"
      ],
      "metadata": {
        "id": "YNL_kPdbKe-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "jmvo43UTKfPR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fJ9dhHtw1sM"
      },
      "source": [
        "# 2.1 Get information for annotations: Table 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For droplet model"
      ],
      "metadata": {
        "id": "FjBbceZHkik-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvH_QsQWwzPk"
      },
      "source": [
        "# %cd /content/droplet_detection\n",
        "\n",
        "# # drop_labels() returns a list of the counted labels: [drop_0cell, drop_1cell, drop_2cell, drop_3cell, images]\n",
        "# totals = []\n",
        "\n",
        "# totals.append(funcs.drop_labels('train/labels','Train'))\n",
        "\n",
        "# totals.append(funcs.drop_labels('valid/labels','Validation'))\n",
        "\n",
        "# totals.append(funcs.drop_labels('test/labels','Test'))\n",
        "\n",
        "# totals = np.array(totals)\n",
        "\n",
        "# print(\"Total Count\")\n",
        "# print(\"drop_0cell: \" + str(np.sum(totals[:,0])))\n",
        "# print(\"drop_1cell: \" + str(np.sum(totals[:,1])))\n",
        "# print(\"drop_2cell: \" + str(np.sum(totals[:,2])))\n",
        "# print(\"drop_3cell: \" + str(np.sum(totals[:,3])))\n",
        "# print(\"combined: \" + str(np.sum(totals[:,0:4])))\n",
        "# print(\"images: \" + str(np.sum(totals[:,4])))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For cell model"
      ],
      "metadata": {
        "id": "6wQE08Ttkl6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "\n",
        "# # cell_labels returns a list of the counted labels: [drop_0cell, drop_1cell, drop_2cell, drop_3cell]\n",
        "# totals = []\n",
        "\n",
        "# totals.append(funcs.cell_labels('train/labels','Train'))\n",
        "\n",
        "# totals.append(funcs.cell_labels('valid/labels','Validation'))\n",
        "\n",
        "# totals.append(funcs.cell_labels('test/labels','Test'))\n",
        "\n",
        "# totals = np.array(totals)\n",
        "\n",
        "# print(\"Total Count\")\n",
        "# print(\"combined: \" + str(np.sum(totals[:,0])))\n",
        "# print(\"images: \" + str(np.sum(totals[:,1])))"
      ],
      "metadata": {
        "id": "_RcPZK5ckoZ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Save Images for Annotation Examples: Figure ann"
      ],
      "metadata": {
        "id": "0ZK7u2FsdW_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For droplet model"
      ],
      "metadata": {
        "id": "yiRhvPabtkKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# funcs.save_labels('train/images', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "\n",
        "# gts = sorted(os.listdir('/label_results/gts'))\n",
        "# files.download('/label_results/gts/{}'.format(gts[1]))"
      ],
      "metadata": {
        "id": "rcwD62zE5sK0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For cell model"
      ],
      "metadata": {
        "id": "tGO7Gnoltq74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# funcs.save_labels('train/images', 'cell', gt_colors=[(0, 255, 0)])\n",
        "\n",
        "# gts = sorted(os.listdir('/label_results/gts'))\n",
        "# files.download('/label_results/gts/{}'.format(gts[3]))\n",
        "# files.download('/label_results/gts/{}'.format(gts[7]))\n",
        "# files.download('/label_results/gts/{}'.format(gts[9]))"
      ],
      "metadata": {
        "id": "mW30SUPT-eVJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMyc3q4RBeV7"
      },
      "source": [
        "# 3. Save cropped droplets with one or more cells and upload this to roboflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB04ItWXBe6y"
      },
      "source": [
        "# # Now convert ground truth labels and boxes\n",
        "# %cd /content/droplet_detection/yolov3\n",
        "\n",
        "# # Using the un-augmented dataset save around 2300 images from training, validation, and test droplets with 1 or more cells in them\n",
        "# # I am sorry this isn't reproducable, I can't remember what I did here. Apparently I only uploaded 2,063 images but when I run this code now it saves 2,269 images.\n",
        "# # This is what the code was supposed to be like though: \n",
        "\n",
        "# tot_saved = funcs.save_cropped(datasets = [\"train\", \"valid\", \"test\"], counter_tot = 0)\n",
        "\n",
        "# !rm /cropped_drops.zip\n",
        "# !zip -r /cropped_drops.zip /cropped_drops\n",
        "# clear_output()\n",
        "\n",
        "# print(\"Number of total images saved from train, validation, and test sets: \",tot_saved)\n",
        "# files.download(\"/cropped_drops.zip\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqvf2AWuDVlI"
      },
      "source": [
        "# 4.1 Train\n",
        "\n",
        "Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv3 from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATC8z86JDZwq"
      },
      "source": [
        "Train a YOLOv3 model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov3.pt`, or from randomly initialized `--weights '' --cfg yolov3.yaml`. Models are downloaded automatically from the [latest YOLOv3 release](https://github.com/ultralytics/yolov3/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
        "\n",
        "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIau9GHuDcYL"
      },
      "source": [
        "# # # Train YOLOv3 on custom dataset. This is currently not working, will have to use ultralytics repository for now: https://github.com/ultralytics/yolov3\n",
        "# # # I have made an issue on yolov3 repository to hopefully fix the issue\n",
        "# %cd /content/droplet_detection_temp/yolov3\n",
        "# !python train.py --img 544 --batch 32 --epochs 800 --data ../yaml_files/droplet_model.yaml --weights '' --cfg models/yolov3.yaml --cache"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK343yD6HULj"
      },
      "source": [
        "# %cp /content/droplet_detection/yolov3/runs/train/exp/weights/best.pt /content/drive/MyDrive/droplet_classification/data_files/yolov3_cell_weights_46_best.pt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Generate high quality mAP plots for validation set"
      ],
      "metadata": {
        "id": "9IfWKlyATQRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# funcs.save_map(results_path=\"/content/drive/MyDrive/droplet_classification/data_files/yolov3_cell_train.csv\", title=\"YOLOv3\", epoch=250)\n",
        "# files.download(\"/mAP_yolov3.png\")"
      ],
      "metadata": {
        "id": "PukCi44lSz3B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1 mAP calculation for droplet model test set: Table 3"
      ],
      "metadata": {
        "id": "q5vAcsQdsLbE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CEtgforYJHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7fb0aaa-10d7-47f4-ce37-ff42a3882663"
      },
      "source": [
        "# Run YOLOv3 on COCO test-dev2017 using --task test\n",
        "%cd /content/droplet_detection/yolov3\n",
        "!rm -r runs/val/exp\n",
        "!python val.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_droplet_367_best.pt --img 544 --data ../yaml_files/droplet_model.yaml --task test\n",
        "\n",
        "# # Download Figures\n",
        "# files.download('runs/val/exp/confusion_matrix.tif')\n",
        "# files.download(\"runs/val/exp/PR_curve.png\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/droplet_detection/yolov3\n",
            "rm: cannot remove 'runs/val/exp': No such file or directory\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=../yaml_files/droplet_model.yaml, weights=['/content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_droplet_367_best.pt'], batch_size=32, imgsz=544, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv3 ðŸš€ fe3f3a1 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61513585 parameters, 0 gradients, 154.6 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '../test/labels' images and labels...128 found, 0 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 1680.15it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: ../test/labels.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:11<00:00,  2.86s/it]\n",
            "                 all        128       2335      0.943      0.941      0.965      0.906\n",
            "          drop_0cell        128        585      0.971      0.964      0.982       0.92\n",
            "          drop_1cell        128        669      0.934       0.95      0.964      0.903\n",
            "          drop_2cell        128        559      0.913      0.919       0.95      0.892\n",
            "          drop_3cell        128        522      0.955      0.931      0.964      0.909\n",
            "Speed: 0.2ms pre-process, 26.1ms inference, 4.6ms NMS per image at shape (32, 3, 544, 544)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcT8Ft4ZDlp3"
      },
      "source": [
        "# 5.2 mAP calculation for cell model test set: Table 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kVUWAbDmSU"
      },
      "source": [
        "# # Run YOLOv3 on COCO test-dev2017 using --task test\n",
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/val/exp\n",
        "# !python val.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_cell_250_best.pt --img 544 --data /content/droplet_detection/yaml_files/cell_model.yaml --task test\n",
        "# # files.download('runs/val/exp/confusion_matrix.tif')\n",
        "# # files.download(\"runs/val/exp/PR_curve.png\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Ground truth labels vs predictions for droplet model test set"
      ],
      "metadata": {
        "id": "wyyTHIstpFgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_droplet_367_best.pt --img 544 --conf-thres 0.6 --source ../test/images --save-txt --save-conf\n",
        "\n",
        "# funcs.save_labels('../test/images', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "\n",
        "# !rm -r /supplemental\n",
        "# os.mkdir('/supplemental')\n",
        "# image_files = sorted(os.listdir(\"/label_results/gts\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# # random.seed(5) may have changed over time. This was the output of random.sample(image_files, 6) at the time of writing:\n",
        "# # ['test_05101_Cam_V710_Cine1_png.rf.1eb83d34828ff0be3c78dcc8e67277ee.png', 'test_07501_Cam_V710_Cine1_png.rf.e43f59e3156132404c614a47d92ea973.png', 'test_15701_Cam_V710_Cine1_png.rf.1e44121ec27f5dbb8a4684d760503968.png', 'test_00151_Cam_V710_Cine1_png.rf.9eb3e2d8f65a839a5aa801f3cce45109.png', 'test_14301_Cam_V710_Cine1_png.rf.b1ee4cee71bebd4d675bb740c035f8a2.png', 'test_04401_Cam_V710_Cine1_png.rf.42cd4c22371045fa5e9595ce7f3bd5f3.png']\n",
        "\n",
        "# for i, image_file in enumerate(random.sample(image_files, 6)):\n",
        "#   shutil.copy('/label_results/inputs/' + image_file, '/supplemental/im_{}_input.png'.format(i))\n",
        "#   shutil.copy('/label_results/gts/' + image_file, '/supplemental/im_{}_gt.png'.format(i))\n",
        "#   shutil.copy('/label_results/preds/' + image_file, '/supplemental/im_{}_pred.png'.format(i))\n",
        "\n",
        "# !rm /supplemental.zip\n",
        "# !zip -r /supplemental.zip /supplemental\n",
        "# clear_output()\n",
        "\n",
        "# files.download('/supplemental.zip')\n",
        "# files.download(\"/label_results/gts/\" + image_files[60])\n",
        "# files.download(\"/label_results/preds/\" + image_files[60])"
      ],
      "metadata": {
        "id": "8Eq1tpbXpFqr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Ground truth labels vs predictions for cell model test set"
      ],
      "metadata": {
        "id": "kKK8p2K1PLBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_cell_46_best.pt --img 544 --source ../test/images --save-txt --save-conf\n",
        "\n",
        "# funcs.save_labels('../test/images', 'cell', gt_colors=[(0,255,0)], pred_colors=[(0,0,255)])\n",
        "\n",
        "# !rm -r /supplemental\n",
        "# os.mkdir('/supplemental')\n",
        "# image_files = sorted(os.listdir(\"/label_results/gt_preds\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# # random.seed(5) may have changed over time. This was the output of random.sample(image_files, 9) at the time of writing:\n",
        "# # ['im_560_png.rf.9be312f06ad6550b281ca07b2a5c13b7.png', 'im_1652_png.rf.ccf3cf1f1d1154629fd3f484e48b3456.png', 'im_827_png.rf.c77873417063e862784767be6d8a0600.png', 'im_1861_png.rf.8df836204d372edeca549bb57873c469.png', 'im_966_png.rf.c92479661a63aa143868826b6e86eece.png', 'im_670_png.rf.769f38911f86bfb8a53142193829d615.png', 'im_585_png.rf.85a4fba0c09c124c95e94c2c39d38bbc.png', 'im_323_png.rf.4bcb0675103e633850717e28d2f0714a.png', 'im_1064_png.rf.aadd049e1248d84477dc1ab064aed391.png']\n",
        "\n",
        "# for image_file in random.sample(image_files, 9):\n",
        "#   shutil.copy('/label_results/gt_preds/' + image_file, '/supplemental')\n",
        "\n",
        "# !rm /supplemental.zip\n",
        "# !zip -r /supplemental.zip /supplemental\n",
        "# clear_output()\n",
        "\n",
        "# files.download('/supplemental.zip')\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[1])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[11])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[68])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[96])"
      ],
      "metadata": {
        "id": "q6MDJg8JPa-t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 Conduct average run times across test set to get FPS: Table 3, 4"
      ],
      "metadata": {
        "id": "NN_IzzPspTyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_cell_250_best.pt --img 544 --conf-thres 0.6 --source=../test/images"
      ],
      "metadata": {
        "id": "6VozZYbUpT9g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qFYqpthISNe"
      },
      "source": [
        "# 7.2 Computer Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh6G9DN6_WEc"
      },
      "source": [
        "# !nvidia-smi -L\n",
        "# !nvidia-smi"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYU4zzjODXBy"
      },
      "source": [
        "# !lscpu |grep 'Model name'\n",
        "\n",
        "# #no.of sockets i.e available slots for physical processors\n",
        "# !lscpu | grep 'Socket(s):'\n",
        "\n",
        "# #no.of cores each processor is having \n",
        "# !lscpu | grep 'Core(s) per socket:'\n",
        "\n",
        "# #no.of threads each core is having\n",
        "# !lscpu | grep 'Thread(s) per core'\n",
        "\n",
        "# !lscpu | grep \"L3 cache\" \n",
        "\n",
        "# #if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "# !lscpu | grep \"MHz\"\n",
        "\n",
        "# #memory that we can use\n",
        "# !free -h --si | awk  '/Mem:/{print $2}'\n",
        "\n",
        "# #hard disk space that we can use\n",
        "# !df -h / | awk '{print $4}'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 Compare Production Set with Hand Counted Percentages: Figure hcomp"
      ],
      "metadata": {
        "id": "K-ZWiAWPc6bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 500 images from second trial and compare droplet ratios with hand counting (Trial 1)"
      ],
      "metadata": {
        "id": "VrgmIM8Bc6dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# rand_int = random.randint(0,9)\n",
        "# # rand_int for seed(5) was 9\n",
        "# production_images = production_images_all[1000+50*rand_int : 1000+50*rand_int+50]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6/' + image, 'data/production_images')\n",
        "\n",
        "# # !zip -r /hand_count.zip /content/droplet_detection/yolov3/data/production_images\n",
        "# # files.download(\"/hand_count.zip\")\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# print('random integer: ',rand_int)\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "8eHjrT2TdEI9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 500 images from third trial and compare droplet ratios with hand counting (Trial 2)"
      ],
      "metadata": {
        "id": "lflJDNcCdEza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# rand_int = random.randint(0,9)\n",
        "# # rand_int for seed(5) was 9\n",
        "# production_images = production_images_all[1000+50*rand_int : 1000+50*rand_int+50]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/' + image, 'data/production_images')\n",
        "\n",
        "# # !zip -r /hand_count.zip /content/droplet_detection/yolov3/data/production_images\n",
        "# # files.download(\"/hand_count.zip\")\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# print('random integer: ',rand_int)\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "1PEkXEQPdUte"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot ML vs Hand Distribution Curves"
      ],
      "metadata": {
        "id": "SnOPYAIqdVtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Grab fractions from .csv file, row is trials and column is droplets... my brain hurts after this one\n",
        "# totals = np.zeros((20,5))\n",
        "# with open('/content/drive/MyDrive/droplet_classification/data_files/yolov3_drop_fractions.csv', newline='') as csvfile:\n",
        "#   spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#   for i, row in enumerate(spamreader):\n",
        "#     if i % 6 == 0:\n",
        "#       continue\n",
        "#     totals[int((i-1)/6), int((i-1)%6)] = int(row[1])\n",
        "# ML_fractions = totals[:, 0:-1] / totals[:, -1, None]\n",
        "\n",
        "# trial = [1,3]\n",
        "# # trial = [0,2]\n",
        "# for i in range(2):\n",
        "#   # Grab fractions from .csv file, row is images and column is droplets\n",
        "#   totals = np.zeros((500,4))\n",
        "#   with open(f'/content/drive/MyDrive/droplet_classification/data_files/hand_count_trial{i+1}.csv', newline='') as csvfile:\n",
        "#     spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#     next(spamreader)\n",
        "#     for j, row in enumerate(spamreader):\n",
        "#       totals[j, :] = [int(row[1]), int(row[2]), int(row[3]), int(row[4])]\n",
        "\n",
        "#   random.seed(5)\n",
        "#   rand_int = random.randint(0,9)\n",
        "#   # rand_int for seed(5) was 9\n",
        "#   BH_fractions = np.sum(totals[50*rand_int : 50*rand_int+50], axis=0) / np.sum(totals[50*rand_int : 50*rand_int+50])\n",
        "#   # BH_fractions = np.sum(totals, axis=0) / np.sum(totals)\n",
        "\n",
        "#   K = [0,1,2,3]\n",
        "#   plt.plot(K,[ML_fractions[trial[i],0],ML_fractions[trial[i],1],ML_fractions[trial[i],2],ML_fractions[trial[i],3]], marker='o', color='r', label=\"YOLOv3 Model\")\n",
        "#   plt.plot(K,[BH_fractions[0],BH_fractions[1],BH_fractions[2],BH_fractions[3]], marker='o', color='g', label='Hand Counted')\n",
        "\n",
        "#   plt.xticks(K,(\"0\",\"1\",\"2\",r'$\\geq3$'))\n",
        "#   plt.tick_params(labelsize=16)\n",
        "#   plt.xlabel(\"k\", fontsize=18)\n",
        "#   plt.ylabel(\"% of Droplets\",fontsize=18)\n",
        "#   plt.title(f'Trial {i+1}: ' u'\\u2248' ' 0-0.5 seconds (50 images)',fontsize=18)\n",
        "#   # plt.title(f'Trial {i+1}: ' u'\\u2248' ' 0-5 seconds (500 images)',fontsize=18)\n",
        "#   plt.legend(loc='lower right',fontsize=15)\n",
        "\n",
        "#   plt.savefig(f'/trial_{i+1}.png',dpi=500,bbox_inches='tight')\n",
        "#   files.download(f'/trial_{i+1}.png')\n",
        "#   plt.clf()"
      ],
      "metadata": {
        "id": "rQaJh2PsdV2p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXb3ufUMn1LB"
      },
      "source": [
        "# 8.2 Compare Production Set with Poisson Distribution: Figure pcomp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For second trial of experimental images between 0-6 minutes (11/9/2021)"
      ],
      "metadata": {
        "id": "fmgaSBTqnN8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6\"))\n",
        "# production_images = production_images_all[9000:15400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "zcRuxhFSLGfK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For second trial of images between 87-89 minutes (11/9/2021)"
      ],
      "metadata": {
        "id": "UbAYDIJ3y46r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_87-89\"))\n",
        "# production_images = production_images_all[0:6400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_87-89/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "GCpCkElEy5G3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For third trial of images between 0-3 minutes (11/15/2021)"
      ],
      "metadata": {
        "id": "0x0RIWKZu1_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3\"))\n",
        "# production_images = production_images_all[3000:9400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "dk6jFDY7u2KE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For third trial of images between 59-60 minutes (11/15/2021)"
      ],
      "metadata": {
        "id": "me8W3meO1GXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_59-60\"))\n",
        "# # production_images = production_images_all[0:6400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_59-60/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "WeHWkLuD1GlQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Poisson Distribution Curves"
      ],
      "metadata": {
        "id": "DGpPxYkpS8oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate concentration and droplet volume\n",
        "# c_0 = 7e6\n",
        "# d = 74e-6\n",
        "# v_0 = (4/3)*math.pi*(d/2)**3\n",
        "# v_0 = v_0*10**6\n",
        "\n",
        "# # Calculate lambda as the expected value or the average number of cells per nanoliter drop\n",
        "# lam = c_0*v_0\n",
        "\n",
        "# Pr = []\n",
        "# K = [0,1,2]\n",
        "# for k in K:\n",
        "#   Pr.append((lam**k)*math.exp(-1*lam)/math.factorial(k))\n",
        "# K.append(3)\n",
        "# Pr.append(1-sum(Pr))\n",
        "\n",
        "# # Grab fractions from .csv file, row is trials and column is droplets... my brain hurts after this one\n",
        "# totals = np.zeros((20,5))\n",
        "# with open('/content/drive/MyDrive/droplet_classification/data_files/yolov3_drop_fractions.csv', newline='') as csvfile:\n",
        "#   spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#   for i, row in enumerate(spamreader):\n",
        "#     if i % 6 == 0:\n",
        "#       continue\n",
        "#     totals[int((i-1)/6), int((i-1)%6)] = float(row[1])\n",
        "# fractions = totals[:, 0:-1] / totals[:, -1, None]\n",
        "\n",
        "# # Which row (section) in csv file to grab from\n",
        "# # t_1 = 4\n",
        "# # t_2 = 8\n",
        "# t_1 = 12\n",
        "# t_2 = 16\n",
        "# plt.errorbar(K,[fractions[t_1,0],fractions[t_1,1],fractions[t_1,2],fractions[t_1,3]], yerr=np.std(fractions[t_1+1:t_1+4], 0), capsize=3,\n",
        "#               marker='o', markersize=5, color='r', label=\"YOLOv3 \" u\"\\u2248\" \" 0-64 seconds\")\n",
        "# plt.errorbar(K,[fractions[t_2,0],fractions[t_2,1],fractions[t_2,2],fractions[t_2,3]], yerr=np.std(fractions[t_2+1:t_2+4], 0), capsize=3, \n",
        "#               marker='o', markersize=5, color='maroon', label=\"YOLOv3 \" u\"\\u2248\" \" 3600-3664 seconds\")\n",
        "# plt.plot(K,Pr, marker='o', markersize=5, color='b', label='Poisson Distribution')\n",
        "\n",
        "# plt.xticks(K,('0','1','2','>3'))\n",
        "# plt.tick_params(labelsize=16)\n",
        "# plt.xlabel('k', fontsize=18)\n",
        "# plt.ylabel('P(x=k)', fontsize=18)\n",
        "# plt.title(\"Trial 2: 12800 images\", fontsize=18)\n",
        "\n",
        "# plt.legend(fontsize=12)\n",
        "\n",
        "# plt.savefig(\"/trial_2.png\",dpi=500,bbox_inches='tight')\n",
        "# files.download(\"/trial_2.png\")"
      ],
      "metadata": {
        "id": "z5yWJGV6RyDm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.1 Conduct inference on production set with both models: Figure ework"
      ],
      "metadata": {
        "id": "bVDra5jHPQAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# from utils.general import xywhn2xyxy\n",
        "# !rm -r data/production\n",
        "# !rm -r runs/detect/exp\n",
        "\n",
        "# prod_image = \"test_03002_Cam_V710_Cine1.png\"\n",
        "# os.mkdir(\"data/production\")\n",
        "# shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/'+prod_image,'data/production')\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source data/production --save-txt --save-conf \n",
        "\n",
        "# funcs.save_labels('data/production', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "# shutil.copy('/label_results/preds/' + prod_image, '/')\n",
        "\n",
        "# !rm -r runs/cropped_drops\n",
        "# os.mkdir('runs/cropped_drops')\n",
        "# with open('runs/detect/exp/labels/' + prod_image[:-4] + '.txt') as f:\n",
        "#   boxes = []\n",
        "#   for i, line in enumerate(f.readlines()):\n",
        "#     line = line.split()\n",
        "#     x = float(line[1])\n",
        "#     y = float(line[2])\n",
        "#     mean_wh = (float(line[3])+float(line[4]))/2\n",
        "#     if x + mean_wh/2 > 1:\n",
        "#       x = 1 - mean_wh/2\n",
        "#     if y + mean_wh/2 > 1:\n",
        "#       y = 1 - mean_wh/2\n",
        "#     if x-mean_wh/2 < 0:\n",
        "#       x = mean_wh/2\n",
        "#     if y-mean_wh/2 < 0:\n",
        "#       y = mean_wh/2\n",
        "#     boxes.append([x,y,mean_wh,mean_wh])\n",
        "#   boxes = xywhn2xyxy(np.array(boxes), w=544, h=544)\n",
        "#   im = cv2.imread('data/production/'+prod_image)\n",
        "#   for i in range(boxes.shape[0]):\n",
        "#     # May not be square by one pixel... make square\n",
        "#     if int(boxes[i,3])-int(boxes[i,1]) < int(boxes[i,2])-int(boxes[i,0]):\n",
        "#       boxes[i,3] += 1\n",
        "#     if int(boxes[i,3])-int(boxes[i,1]) > int(boxes[i,2])-int(boxes[i,0]):\n",
        "#       boxes[i,2] += 1\n",
        "#     cropped_resized = cv2.resize(im[int(boxes[i,1]):int(boxes[i,3]),int(boxes[i,0]):int(boxes[i,2])],(544, 544))\n",
        "#     cv2.imwrite(\"runs/cropped_drops/cropped_drop_\"+str(i)+\".png\",cropped_resized)\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_cell_46_best.pt --img 544 --conf-thres 0.6 --source runs/cropped_drops --save-txt --save-conf\n",
        "# clear_output()\n",
        "\n",
        "# funcs.save_labels('runs/cropped_drops', 'cell', pred_labels = 'cell ')\n",
        "# files.download('/' + prod_image)\n",
        "# files.download(\"/label_results/inputs/cropped_drop_28.png\")\n",
        "# files.download(\"/label_results/preds/cropped_drop_28.png\")"
      ],
      "metadata": {
        "id": "t5C8dIx0PQL-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.2 Alternative inference on production set with both models"
      ],
      "metadata": {
        "id": "Mt4t4YIWpMnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# The paper was already written and model was trained, however this would probably have been the better option\n",
        "# to train and predict the cropped droplets... shoot maybe next round I will do this but this would have been cool\n",
        "# to add in the paper!  The idea is to pad the extra height or with with the average pixel value from the image. \n",
        "# This way I am not taking some of another droplet with a half droplet that is cropped on the edge of the image.\n",
        "# Still works for detecting though! \n",
        "# \"\"\"\n",
        "\n",
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/cropped_drops\n",
        "# !rm -r runs/detect/exp\n",
        "# !rm -r runs/detect/exp2\n",
        "\n",
        "\n",
        "# prod_image = \"test_03002_Cam_V710_Cine1.png\"\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_243_best.pt --img 544 --conf-thres 0.6 --source /content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/{prod_image} --line-thickness 2 --hide-labels --hide-conf --save-crop\n",
        "# files.download(\"runs/detect/exp/\" + prod_image)\n",
        "\n",
        "# count = 0\n",
        "# !mkdir runs/cropped_drops\n",
        "# for i in range(4):\n",
        "#   for im_file in os.listdir('runs/detect/exp/crops/drop_{}cell'.format(i)):\n",
        "#     image = cv2.imread('runs/detect/exp/crops/drop_{}cell/{}'.format(i,im_file))\n",
        "#     mean = np.mean(image)\n",
        "#     h = image.shape[0]\n",
        "#     w = image.shape[1]\n",
        "#     if h > w:\n",
        "#       padded = np.zeros((h, h, 3))\n",
        "#       l = int((h-w)/2)\n",
        "#       padded[:,0:l,:] = mean\n",
        "#       padded[:,l:l+w,:] = image\n",
        "#       padded[:,l+w:,:] = mean\n",
        "#     elif w > h:\n",
        "#       padded = np.zeros((w, w, 3))\n",
        "#       l = int((w-h)/2)\n",
        "#       padded[0:l,:,:] = mean\n",
        "#       padded[l:l+h,:,:] = image\n",
        "#       padded[l+h:,:,:] = mean\n",
        "#     else:\n",
        "#       padded = image.copy()\n",
        "\n",
        "#     cv2.imwrite('runs/cropped_drops/im_{}.png'.format(count), cv2.resize(padded,(544,544)))\n",
        "#     count += 1\n",
        "\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov3_weights_cell_46_best.pt --img 544 --conf-thres 0.6 --source runs/cropped_drops --hide-labels --hide-conf\n"
      ],
      "metadata": {
        "id": "OI8Q8-RvuMuq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.3 Construct Poisson Curve for multiple lambdas: Figure ework"
      ],
      "metadata": {
        "id": "AS9yA7NPUuCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prs = []\n",
        "# lambdas = [1,3,6,9]\n",
        "# colors = [\"r\",\"g\",\"b\",\"black\",]\n",
        "# K = list(range(0,21,1))\n",
        "\n",
        "\n",
        "# for lam,c in zip(lambdas,colors):\n",
        "#   Pr = []\n",
        "#   for k in K:\n",
        "#     Pr.append((lam**k)*math.exp(-1*lam)/math.factorial(k))\n",
        "\n",
        "#   plt.plot(K,Pr, markersize=3.5,marker='o', color=c, label=\"\\u03BB = \" + str(lam))\n",
        "\n",
        "\n",
        "# plt.xticks([0,5,10,15,20],[\"0\",\"5\",\"10\",\"15\",\"20\"])\n",
        "# plt.yticks([0.0,0.1,0.2,0.3,0.4],[\"0.0\",\"0.1\",\"0.2\",\"0.2\",\"0.3\",\"0.4\"])\n",
        "# plt.xlabel(\"k\", fontsize=30, fontname=\"Arial\")\n",
        "# plt.ylabel(\"$p_{k}$\", fontsize=30, fontname=\"Arial\")\n",
        "# plt.tick_params(axis='both', which='major', labelsize=25)\n",
        "\n",
        "# plt.legend(fontsize=20)\n",
        "# # plt.subplots_adjust(right=0.1)\n",
        "# plt.savefig(\"/poisson_distribution.png\",dpi=500,bbox_inches='tight')\n",
        "# files.download(\"/poisson_distribution.png\")"
      ],
      "metadata": {
        "id": "BRN6OLG0UuNx"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}