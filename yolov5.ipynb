{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY7FqFiNVF02B4Eh++uy4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karl-gardner/droplet_detection/blob/master/yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQkghdbzJR2o"
      },
      "source": [
        "<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "<img width=\"1024\", src=\"https://user-images.githubusercontent.com/26833433/125273437-35b3fc00-e30d-11eb-9079-46f313325424.png\"></a>\n",
        "\n",
        "This is the **official YOLOv5 ðŸš€ notebook** by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HysLjSKjKA08"
      },
      "source": [
        "# 0. Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Ohn5yXJSrl",
        "outputId": "ead1a81e-de65-4af4-df35-cd75dd320617"
      },
      "source": [
        "!git clone https://github.com/karl-gardner/droplet_detection  # clone repo\n",
        "%cd /content/droplet_detection/yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from google.colab import files\n",
        "import random\n",
        "import csv\n",
        "\n",
        "%cd /content/droplet_detection\n",
        "import funcs\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9APKIDtzKpJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278a1231-5541-4168-93ca-d3f96672e8e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF7fnR0oAV56"
      },
      "source": [
        "# 1.1 Droplet model dataset from roboflow (PC3DropletDetection2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data With Augmentation for Training (final_dataset)"
      ],
      "metadata": {
        "id": "X8nHU2NJzz4V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhn2U849AWNr"
      },
      "source": [
        "%cd /content/droplet_detection\n",
        "!curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data with No Augmentation (No_Augmentation)"
      ],
      "metadata": {
        "id": "R-bu4cGtz6p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "puTXkA3Dz61A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Cell model dataset from roboflow (Cropped_Drops2)"
      ],
      "metadata": {
        "id": "3ajCvL85Ow_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data With Augmentation for Training (final_dataset)"
      ],
      "metadata": {
        "id": "kcrj_kiHOxiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "iyyVMQkfO0eX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data with No Augmentation (No_Augmentation)"
      ],
      "metadata": {
        "id": "qQlbjWFrO4G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# !curl -L \"[ROBOFLOW-API-KEY]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "# clear_output()"
      ],
      "metadata": {
        "id": "d0HBMtDOO6Jj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Get information for annotations: Table 2."
      ],
      "metadata": {
        "id": "kHhMYYnUKPzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For droplet model"
      ],
      "metadata": {
        "id": "dXAynTgpKWXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "\n",
        "# # drop_labels() returns a list of the counted labels: [drop_0cell, drop_1cell, drop_2cell, drop_3cell, images]\n",
        "# totals = []\n",
        "\n",
        "# totals.append(funcs.drop_labels('train/labels','Train'))\n",
        "\n",
        "# totals.append(funcs.drop_labels('valid/labels','Validation'))\n",
        "\n",
        "# totals.append(funcs.drop_labels('test/labels','Test'))\n",
        "\n",
        "# totals = np.array(totals)\n",
        "\n",
        "# print(\"Total Count\")\n",
        "# print(\"drop_0cell: \" + str(np.sum(totals[:,0])))\n",
        "# print(\"drop_1cell: \" + str(np.sum(totals[:,1])))\n",
        "# print(\"drop_2cell: \" + str(np.sum(totals[:,2])))\n",
        "# print(\"drop_3cell: \" + str(np.sum(totals[:,3])))\n",
        "# print(\"combined: \" + str(np.sum(totals[:,0:4])))\n",
        "# print(\"images: \" + str(np.sum(totals[:,4])))"
      ],
      "metadata": {
        "id": "9lgyKHtlKSve"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For cell model"
      ],
      "metadata": {
        "id": "aGoBpXoRKeQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "\n",
        "# # cell_labels returns a list of the counted labels: [drop_0cell, drop_1cell, drop_2cell, drop_3cell]\n",
        "# totals = []\n",
        "\n",
        "# totals.append(funcs.cell_labels('train/labels','Train'))\n",
        "\n",
        "# totals.append(funcs.cell_labels('valid/labels','Validation'))\n",
        "\n",
        "# totals.append(funcs.cell_labels('test/labels','Test'))\n",
        "\n",
        "# totals = np.array(totals)\n",
        "\n",
        "# print(\"Total Count\")\n",
        "# print(\"combined: \" + str(np.sum(totals[:,0])))\n",
        "# print(\"images: \" + str(np.sum(totals[:,1])))"
      ],
      "metadata": {
        "id": "ED3b76vhKU5g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Save Images for Annotation Examples: Figure ann"
      ],
      "metadata": {
        "id": "uxgJJ-D7Ko1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For droplet model"
      ],
      "metadata": {
        "id": "S0PONzMQKrf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# funcs.save_labels('train/images', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "\n",
        "# gts = sorted(os.listdir('/label_results/gts'))\n",
        "# files.download('/label_results/gts/{}'.format(gts[1]))"
      ],
      "metadata": {
        "id": "vjNktcOSKoO1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For cell model"
      ],
      "metadata": {
        "id": "9AgNr63XKsc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection\n",
        "# funcs.save_labels('train/images', 'cell', gt_colors=[(0, 255, 0)])\n",
        "\n",
        "# gts = sorted(os.listdir('/label_results/gts'))\n",
        "# files.download('/label_results/gts/{}'.format(gts[3]))\n",
        "# files.download('/label_results/gts/{}'.format(gts[7]))\n",
        "# files.download('/label_results/gts/{}'.format(gts[9]))"
      ],
      "metadata": {
        "id": "9LM63y-tKsnL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Save cropped droplets with one or more cells and upload this to roboflow"
      ],
      "metadata": {
        "id": "b8bnAYOtOEcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Now convert ground truth labels and boxes\n",
        "# %cd /content/droplet_detection/yolov3\n",
        "\n",
        "# # Using the un-augmented dataset save around 2300 images from training, validation, and test droplets with 1 or more cells in them\n",
        "# # I am sorry this isn't reproducable, I can't remember what I did here. Apparently I only uploaded 2,063 images but when I run this code now it saves 2,269 images.\n",
        "# # This is what the code was supposed to be like though: \n",
        "\n",
        "# tot_saved = funcs.save_cropped(datasets = [\"train\", \"valid\", \"test\"], counter_tot = 0)\n",
        "\n",
        "# !rm /cropped_drops.zip\n",
        "# !zip -r /cropped_drops.zip /cropped_drops\n",
        "# clear_output()\n",
        "\n",
        "# print(\"Number of total images saved from train, validation, and test sets: \",tot_saved)\n",
        "# files.download(\"/cropped_drops.zip\")"
      ],
      "metadata": {
        "id": "aXI6_oPVOEvx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkkReo_oLCD2"
      },
      "source": [
        "# 4.1 Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615338ba77195c71bd2c5ab1_computer-vision-flow.png\"/></a></p>\n",
        "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
        "<br><br>\n",
        "\n",
        "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
        "\n",
        "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
        "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
        "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
        "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
        "<br><br>\n",
        "\n",
        "## Train on Custom Data with Roboflow ðŸŒŸ NEW\n",
        "\n",
        "[Roboflow](https://roboflow.com/?ref=ultralytics) enables you to easily **organize, label, and prepare** a high quality dataset with your own custom data. Roboflow also makes it easy to establish an active learning pipeline, collaborate with your team on dataset improvement, and integrate directly into your model building workflow with the `roboflow` pip package.\n",
        "\n",
        "- Custom Training Example: [https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/](https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/?ref=ultralytics)\n",
        "- Custom Training Notebook: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/yolov5-custom-training-tutorial/blob/main/yolov5-custom-training.ipynb)\n",
        "<br>\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"480\" src=\"https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/6152a275ad4b4ac20cd2e21a_roboflow-annotate.gif\"/></a></p>Label images lightning fast (including with model-assisted labeling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7hRNPQOLMYe"
      },
      "source": [
        "# # # Train YOLOv5 on custom dataset. This is currently not working, will have to use ultralytics repository for now: https://github.com/ultralytics/yolov5\n",
        "# # # I have made an issue on yolov5 repository to hopefully fix the issue\n",
        "# %cd /content/droplet_detection/yolov5\n",
        "# !python train.py --img 544 --batch 32 --epochs 1 --data '../yaml_files/droplet_model.yaml' --weights '' --cfg ./models/yolov5m.yaml --cache"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOhzdRi7xiL8"
      },
      "source": [
        "# %cp /content/droplet_detection/yolov5/runs/train/exp/weights/best.pt /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_365_best.pt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 High quality mAP plots for validation set"
      ],
      "metadata": {
        "id": "v6v9ZsvF8Kpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# funcs.save_map(results_path = \"/content/drive/MyDrive/droplet_classification/data_files/yolov5_cell_train.csv\", title=\"YOLOv5\", epoch=38)\n",
        "# files.download(\"/mAP_yolov5.png\")"
      ],
      "metadata": {
        "id": "xbPlEjodX-5m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH3wycG3Zisv"
      },
      "source": [
        "# 5.1 mAP calculation for droplet model test set: Table drop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgauumJZlCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b732a64a-18fa-4da0-8b04-e3f4884b420f"
      },
      "source": [
        "# Run YOLOv5s on COCO test-dev2017 using --task test\n",
        "%cd /content/droplet_detection/yolov5\n",
        "!python val.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --data ../yaml_files/droplet_model.yaml --task test\n",
        "\n",
        "# # Download Figures\n",
        "# files.download('runs/val/exp/confusion_matrix.tif')\n",
        "# files.download(\"runs/val/exp/PR_curve.png\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/droplet_detection/yolov5\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=../yaml_files/droplet_model.yaml, weights=['/content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt'], batch_size=32, imgsz=544, conf_thres=0.001, iou_thres=0.6, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ 2022-8-23 torch 1.12.1+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 47.6MB/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/droplet_detection/yolov5/../test/labels' images and labels...128 found, 0 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<00:00, 1427.96it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/droplet_detection/yolov5/../test/labels.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  25% 1/4 [00:02<00:07,  2.53s/it]WARNING: NMS time limit 1.060s exceeded\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:09<00:00,  2.29s/it]\n",
            "                 all        128       2335      0.939      0.946      0.968      0.911\n",
            "          drop_0cell        128        585      0.974      0.959      0.985      0.927\n",
            "          drop_1cell        128        669       0.94      0.957      0.969      0.911\n",
            "          drop_2cell        128        559      0.904      0.925      0.951      0.895\n",
            "          drop_3cell        128        522      0.939      0.944      0.968      0.911\n",
            "Speed: 0.1ms pre-process, 6.2ms inference, 11.6ms NMS per image at shape (32, 3, 544, 544)\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.2 mAP calculation for cell model test set: Table cell"
      ],
      "metadata": {
        "id": "YsAHPGzTLNlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Run YOLOv3 on COCO test-dev2017 using --task test\n",
        "# %cd /content/droplet_detection/yolov5\n",
        "# !rm -r runs/val/exp\n",
        "# !python val.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_cell_38_best.pt --img 544 --data ../yaml_files/cell_model.yaml --task test\n",
        "# # files.download('runs/val/exp/confusion_matrix.tif')\n",
        "# # files.download(\"runs/val/exp/PR_curve.png\")"
      ],
      "metadata": {
        "id": "qGh1cG76LNvE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.1 Ground truth labels vs predictions for droplet model test set: Figure gvpdrop"
      ],
      "metadata": {
        "id": "aJLxQr9NLap8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source ../test/images --save-txt --save-conf\n",
        "\n",
        "# funcs.save_labels('../test/images', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "\n",
        "# !rm -r /supplemental\n",
        "# os.mkdir('/supplemental')\n",
        "# image_files = sorted(os.listdir(\"/label_results/gts\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# # random.seed(5) may have changed over time. This was the output of random.sample(image_files, 6) at the time of writing:\n",
        "\n",
        "# for i, image_file in enumerate(random.sample(image_files, 6)):\n",
        "#   shutil.copy('/label_results/inputs/' + image_file, '/supplemental/im_{}_input.png'.format(i))\n",
        "#   shutil.copy('/label_results/gts/' + image_file, '/supplemental/im_{}_gt.png'.format(i))\n",
        "#   shutil.copy('/label_results/preds/' + image_file, '/supplemental/im_{}_pred.png'.format(i))\n",
        "\n",
        "# !rm /supplemental.zip\n",
        "# !zip -r /supplemental.zip /supplemental\n",
        "# clear_output()\n",
        "\n",
        "# files.download('/supplemental.zip')\n",
        "# files.download(\"/label_results/gts/\" + image_files[109])\n",
        "# files.download(\"/label_results/preds/\" + image_files[109])"
      ],
      "metadata": {
        "id": "k7YUkMMxLb2T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.2 Ground truth labels vs predictions for cell model test set: Figure gvpdrop"
      ],
      "metadata": {
        "id": "NcM6m4jiLrSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_cell_38_best.pt --img 544 --source ../test/images --save-txt --save-conf\n",
        "\n",
        "# funcs.save_labels('../test/images', 'cell', gt_colors=[(0,255,0)], pred_colors=[(0,0,255)])\n",
        "\n",
        "# !rm -r /supplemental\n",
        "# os.mkdir('/supplemental')\n",
        "# image_files = sorted(os.listdir(\"/label_results/gt_preds\"))\n",
        "\n",
        "# random.seed(5)\n",
        "# # random.seed(5) may have changed over time. This was the output of random.sample(image_files, 9) at the time of writing:\n",
        "\n",
        "# for image_file in random.sample(image_files, 9):\n",
        "#   shutil.copy('/label_results/gt_preds/' + image_file, '/supplemental')\n",
        "\n",
        "# !rm /supplemental.zip\n",
        "# !zip -r /supplemental.zip /supplemental\n",
        "# clear_output()\n",
        "\n",
        "# files.download('/supplemental.zip')\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[1])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[11])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[68])\n",
        "# files.download(\"/label_results/gt_preds/\" + image_files[96])"
      ],
      "metadata": {
        "id": "Bxwh2nkeLrcz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA60FSURvOrx"
      },
      "source": [
        "# 7.1 Conduct average run times across test set: Table FPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9zG1-MavQZZ"
      },
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_cell_38_best.pt --img 544 --conf-thres 0.6 --source=../test/images"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LktxWj6PlVxt"
      },
      "source": [
        "# 7.2 Computer Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnAA4aLilU7R"
      },
      "source": [
        "# !nvidia-smi -L\n",
        "# !nvidia-smi"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3WlIpS9laaK"
      },
      "source": [
        "# !lscpu |grep 'Model name'\n",
        "\n",
        "# #no.of sockets i.e available slots for physical processors\n",
        "# !lscpu | grep 'Socket(s):'\n",
        "\n",
        "# #no.of cores each processor is having \n",
        "# !lscpu | grep 'Core(s) per socket:'\n",
        "\n",
        "# #no.of threads each core is having\n",
        "# !lscpu | grep 'Thread(s) per core'\n",
        "\n",
        "# !lscpu | grep \"L3 cache\" \n",
        "\n",
        "# #if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "# !lscpu | grep \"MHz\"\n",
        "\n",
        "# #memory that we can use\n",
        "# !free -h --si | awk  '/Mem:/{print $2}'\n",
        "\n",
        "# #hard disk space that we can use\n",
        "# !df -h / | awk '{print $4}'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 Compare Production Set with Hand Counted Percentages: Figure hcomp"
      ],
      "metadata": {
        "id": "rR9vfTm_MLmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 500 images from second trial and compare droplet ratios with hand counting (Trial 1)"
      ],
      "metadata": {
        "id": "KkjbSEKxMMnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6\"))\n",
        "\n",
        "# # random.seed(5)\n",
        "# # rand_int = random.randint(0,9)\n",
        "# # # rand_int for seed(5) was 9\n",
        "# # production_images = production_images_all[1000+50*rand_int : 1000+50*rand_int+50]\n",
        "# production_images = production_images_all[1000:1500]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6/' + image, 'data/production_images')\n",
        "\n",
        "# # !zip -r /hand_count.zip /content/droplet_detection/yolov5/data/production_images\n",
        "# # files.download(\"/hand_count.zip\")\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# # print('random integer: ',rand_int)\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "mvVlTsluMK92"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 500 images from third trial and compare droplet ratios with hand counting (Trial 2)"
      ],
      "metadata": {
        "id": "i9JtDP3KMSGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3\"))\n",
        "\n",
        "# # random.seed(5)\n",
        "# # rand_int = random.randint(0,9)\n",
        "# # # rand_int for seed(5) was 9\n",
        "# # production_images = production_images_all[1000+50*rand_int : 1000+50*rand_int+50]\n",
        "# production_images = production_images_all[1000:1500]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/' + image, 'data/production_images')\n",
        "\n",
        "# # !zip -r /hand_count.zip /content/droplet_detection/yolov5/data/production_images\n",
        "# # files.download(\"/hand_count.zip\")\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# # print('random integer: ',rand_int)\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "PHuWgAy4MWCG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot ML vs Hand Distribution Curves"
      ],
      "metadata": {
        "id": "9vRgVrlHMZsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Grab fractions from .csv file, row is trials and column is droplets... my brain hurts after this one\n",
        "# totals = np.zeros((20,5))\n",
        "# with open('/content/drive/MyDrive/droplet_classification/data_files/yolov5_drop_fractions.csv', newline='') as csvfile:\n",
        "#   spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#   for i, row in enumerate(spamreader):\n",
        "#     if i % 6 == 0:\n",
        "#       continue\n",
        "#     totals[int((i-1)/6), int((i-1)%6)] = int(row[1])\n",
        "# ML_fractions = totals[:, 0:-1] / totals[:, -1, None]\n",
        "\n",
        "# # trial = [1,3]\n",
        "# trial = [0,2]\n",
        "# for i in range(2):\n",
        "#   # Grab fractions from .csv file, row is images and column is droplets\n",
        "#   totals = np.zeros((500,4))\n",
        "#   with open(f'/content/drive/MyDrive/droplet_classification/data_files/hand_count_trial{i+1}.csv', newline='') as csvfile:\n",
        "#     spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#     next(spamreader)\n",
        "#     for j, row in enumerate(spamreader):\n",
        "#       totals[j, :] = [int(row[1]), int(row[2]), int(row[3]), int(row[4])]\n",
        "\n",
        "#   # rand_int for seed(5) was 9\n",
        "#   rand_int = 9\n",
        "#   # BH_fractions = np.sum(totals[50*rand_int : 50*rand_int+50], axis=0) / np.sum(totals[50*rand_int : 50*rand_int+50])\n",
        "#   BH_fractions = np.sum(totals, axis=0) / np.sum(totals)\n",
        "\n",
        "#   K = [0,1,2,3]\n",
        "#   plt.plot(K,[ML_fractions[trial[i],0],ML_fractions[trial[i],1],ML_fractions[trial[i],2],ML_fractions[trial[i],3]], marker='o', color='r', label=\"YOLOv3 Model\")\n",
        "#   plt.plot(K,[BH_fractions[0],BH_fractions[1],BH_fractions[2],BH_fractions[3]], marker='o', color='g', label='Hand Counted')\n",
        "\n",
        "#   plt.xticks(K,(\"0\",\"1\",\"2\",r'$\\geq3$'))\n",
        "#   plt.tick_params(labelsize=16)\n",
        "#   plt.xlabel(\"k\", fontsize=18)\n",
        "#   plt.ylabel(\"% of Droplets\",fontsize=18)\n",
        "#   plt.title(f'Trial {i+1}: ' u'\\u2248' ' 0-0.5 seconds (50 images)',fontsize=18)\n",
        "#   # plt.title(f'Trial {i+1}: ' u'\\u2248' ' 0-5 seconds (500 images)',fontsize=18)\n",
        "#   plt.legend(loc='lower right',fontsize=15)\n",
        "\n",
        "#   plt.savefig(f'/trial_{i+1}.png',dpi=500,bbox_inches='tight')\n",
        "#   files.download(f'/trial_{i+1}.png')\n",
        "#   plt.clf()"
      ],
      "metadata": {
        "id": "6SlfUlt9MaTi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 Compare Production Set with Poisson Distribution: Figure pcomp"
      ],
      "metadata": {
        "id": "Orczt1j9MdRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For second trial of experimental images between 0-6 minutes (11/9/2021)"
      ],
      "metadata": {
        "id": "iD_0b_PuMkjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov3\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6\"))\n",
        "# production_images = production_images_all[9000:15400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_0-6/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "dDGv-m_xMncU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For second trial of images between 87-89 minutes (11/9/2021)"
      ],
      "metadata": {
        "id": "zXCKOoKQMoGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_87-89\"))\n",
        "# production_images = production_images_all[0:6400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-9-2021_t02_87-89/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "dGCfiXV8Mrai"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For third trial of images between 0-3 minutes (11/15/2021)"
      ],
      "metadata": {
        "id": "bOpKRRcxMtxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3\"))\n",
        "# production_images = production_images_all[3000:9400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "q2RGB_E6Mv7B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For third trial of images between 59-60 minutes (11/15/2021)"
      ],
      "metadata": {
        "id": "SboV49vZMyPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# production_images_all = sorted(os.listdir(\"/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_59-60\"))\n",
        "# production_images = production_images_all[0:6400]\n",
        "\n",
        "# !rm -r data/production_images\n",
        "# !mkdir data/production_images\n",
        "# for image in production_images:\n",
        "#   shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_59-60/' + image, 'data/production_images')\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production_images --save-txt\n",
        "# clear_output()\n",
        "\n",
        "# _ = funcs.drop_labels('runs/detect/exp/labels', 'Production')"
      ],
      "metadata": {
        "id": "TJXmvN4HM0ob"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Poisson Distribution Curves"
      ],
      "metadata": {
        "id": "TeDJARi-M6BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate concentration and droplet volume\n",
        "# c_0 = 7e6\n",
        "# d = 74e-6\n",
        "# v_0 = (4/3)*math.pi*(d/2)**3\n",
        "# v_0 = v_0*10**6\n",
        "\n",
        "# # Calculate lambda as the expected value or the average number of cells per nanoliter drop\n",
        "# lam = c_0*v_0\n",
        "\n",
        "\n",
        "# Pr = []\n",
        "# K = [0,1,2]\n",
        "# for k in K:\n",
        "#   Pr.append((lam**k)*math.exp(-1*lam)/math.factorial(k))\n",
        "# K.append(3)\n",
        "# Pr.append(1-sum(Pr))\n",
        "\n",
        "# # Grab fractions from .csv file, row is trials and column is droplets... my brain hurts after this one\n",
        "# totals = np.zeros((20,5))\n",
        "# with open('/content/drive/MyDrive/droplet_classification/data_files/yolov5_drop_fractions.csv', newline='') as csvfile:\n",
        "#   spamreader = csv.reader(csvfile, quotechar='|')\n",
        "#   for i, row in enumerate(spamreader):\n",
        "#     if i % 6 == 0:\n",
        "#       continue\n",
        "#     totals[int((i-1)/6), int((i-1)%6)] = float(row[1])\n",
        "# fractions = totals[:, 0:-1] / totals[:, -1, None]\n",
        "\n",
        "# # Which row (section) in csv file to grab from\n",
        "# # t_1 = 4\n",
        "# # t_2 = 8\n",
        "# t_1 = 12\n",
        "# t_2 = 16\n",
        "# plt.errorbar(K,[fractions[t_1,0],fractions[t_1,1],fractions[t_1,2],fractions[t_1,3]], yerr=np.std(fractions[t_1+1:t_1+4], 0), capsize=3,\n",
        "#               marker='o', markersize=5, color='r', label=\"YOLOv3 \" u\"\\u2248\" \" 0-64 seconds\")\n",
        "# plt.errorbar(K,[fractions[t_2,0],fractions[t_2,1],fractions[t_2,2],fractions[t_2,3]], yerr=np.std(fractions[t_2+1:t_2+4], 0), capsize=3, \n",
        "#               marker='o', markersize=5, color='maroon', label=\"YOLOv3 \" u\"\\u2248\" \" 5220-5284 seconds\")\n",
        "# plt.plot(K,Pr, marker='o', markersize=5, color='b', label='Poisson Distribution')\n",
        "\n",
        "# plt.xticks(K,('0','1','2','>3'))\n",
        "# plt.tick_params(labelsize=16)\n",
        "# plt.xlabel('k', fontsize=18)\n",
        "# plt.ylabel('P(x=k)', fontsize=18)\n",
        "# plt.title(\"Trial 1: 12800 images\", fontsize=18)\n",
        "\n",
        "# plt.legend(fontsize=12)\n",
        "\n",
        "# plt.savefig(\"/trial_1.png\",dpi=500,bbox_inches='tight')\n",
        "# files.download(\"/trial_1.png\")"
      ],
      "metadata": {
        "id": "Ov-9GvXgM8Dx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.1 Conduct inference on production set with both models: Figure ework"
      ],
      "metadata": {
        "id": "ImqNw3wjNBBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/droplet_detection/yolov5\n",
        "# from utils.general import xywhn2xyxy\n",
        "# !rm -r data/production\n",
        "# !rm -r runs/detect/exp\n",
        "\n",
        "# prod_image = \"test_03002_Cam_V710_Cine1.png\"\n",
        "# os.mkdir(\"data/production\")\n",
        "# shutil.copy('/content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/'+prod_image,'data/production')\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source data/production --save-txt --save-conf \n",
        "\n",
        "# funcs.save_labels('data/production', 'droplet', gt_colors=[(0,0,255), (0,255,255), (0,255, 0), (255,0,255)])\n",
        "# shutil.copy('/label_results/preds/' + prod_image, '/')\n",
        "\n",
        "# !rm -r runs/cropped_drops\n",
        "# os.mkdir('runs/cropped_drops')\n",
        "# with open('runs/detect/exp/labels/' + prod_image[:-4] + '.txt') as f:\n",
        "#   boxes = []\n",
        "#   for i, line in enumerate(f.readlines()):\n",
        "#     line = line.split()\n",
        "#     x = float(line[1])\n",
        "#     y = float(line[2])\n",
        "#     mean_wh = (float(line[3])+float(line[4]))/2\n",
        "#     if x + mean_wh/2 > 1:\n",
        "#       x = 1 - mean_wh/2\n",
        "#     if y + mean_wh/2 > 1:\n",
        "#       y = 1 - mean_wh/2\n",
        "#     if x-mean_wh/2 < 0:\n",
        "#       x = mean_wh/2\n",
        "#     if y-mean_wh/2 < 0:\n",
        "#       y = mean_wh/2\n",
        "#     boxes.append([x,y,mean_wh,mean_wh])\n",
        "#   boxes = xywhn2xyxy(np.array(boxes), w=544, h=544)\n",
        "#   im = cv2.imread('data/production/'+prod_image)\n",
        "#   for i in range(boxes.shape[0]):\n",
        "#     # May not be square by one pixel... make square\n",
        "#     if int(boxes[i,3])-int(boxes[i,1]) < int(boxes[i,2])-int(boxes[i,0]):\n",
        "#       boxes[i,3] += 1\n",
        "#     if int(boxes[i,3])-int(boxes[i,1]) > int(boxes[i,2])-int(boxes[i,0]):\n",
        "#       boxes[i,2] += 1\n",
        "#     cropped_resized = cv2.resize(im[int(boxes[i,1]):int(boxes[i,3]),int(boxes[i,0]):int(boxes[i,2])],(544, 544))\n",
        "#     cv2.imwrite(\"runs/cropped_drops/cropped_drop_\"+str(i)+\".png\",cropped_resized)\n",
        "\n",
        "# !rm -r runs/detect/exp\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_cell_38_best.pt --img 544 --conf-thres 0.6 --source runs/cropped_drops --save-txt --save-conf\n",
        "# clear_output()\n",
        "\n",
        "# funcs.save_labels('runs/cropped_drops', 'cell', pred_labels = 'cell ')\n",
        "# files.download('/' + prod_image)\n",
        "# files.download(\"/label_results/inputs/cropped_drop_1.png\")\n",
        "# files.download(\"/label_results/preds/cropped_drop_1.png\")"
      ],
      "metadata": {
        "id": "FvRfTrYyNDOO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.2 Alternative inference on production set with both models"
      ],
      "metadata": {
        "id": "S9KEnySPNLFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# The paper was already written and model was trained, however this would probably have been the better option\n",
        "# to train and predict the cropped droplets... shoot maybe next round I will do this but this would have been cool\n",
        "# to add in the paper!  The idea is to pad the extra height or with with the average pixel value from the image. \n",
        "# This way I am not taking some of another droplet with a half droplet that is cropped on the edge of the image.\n",
        "# Still works for detecting though! \n",
        "# \"\"\"\n",
        "\n",
        "# %cd /content/droplet_detection/yolov5\n",
        "# !rm -r runs/cropped_drops\n",
        "# !rm -r runs/detect/exp\n",
        "# !rm -r runs/detect/exp2\n",
        "\n",
        "\n",
        "# prod_image = \"test_03002_Cam_V710_Cine1.png\"\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_droplet_374_best.pt --img 544 --conf-thres 0.6 --source /content/drive/MyDrive/droplet_classification/data_files/production_set/data_11-15-2021_t03_0-3/{prod_image} --line-thickness 2 --hide-labels --hide-conf --save-crop\n",
        "# files.download(\"runs/detect/exp/\" + prod_image)\n",
        "\n",
        "# count = 0\n",
        "# !mkdir runs/cropped_drops\n",
        "# for i in range(4):\n",
        "#   for im_file in os.listdir('runs/detect/exp/crops/drop_{}cell'.format(i)):\n",
        "#     image = cv2.imread('runs/detect/exp/crops/drop_{}cell/{}'.format(i,im_file))\n",
        "#     mean = np.mean(image)\n",
        "#     h = image.shape[0]\n",
        "#     w = image.shape[1]\n",
        "#     if h > w:\n",
        "#       padded = np.zeros((h, h, 3))\n",
        "#       l = int((h-w)/2)\n",
        "#       padded[:,0:l,:] = mean\n",
        "#       padded[:,l:l+w,:] = image\n",
        "#       padded[:,l+w:,:] = mean\n",
        "#     elif w > h:\n",
        "#       padded = np.zeros((w, w, 3))\n",
        "#       l = int((w-h)/2)\n",
        "#       padded[0:l,:,:] = mean\n",
        "#       padded[l:l+h,:,:] = image\n",
        "#       padded[l+h:,:,:] = mean\n",
        "#     else:\n",
        "#       padded = image.copy()\n",
        "\n",
        "#     cv2.imwrite('runs/cropped_drops/im_{}.png'.format(count), cv2.resize(padded,(544,544)))\n",
        "#     count += 1\n",
        "\n",
        "# !python detect.py --weights /content/drive/MyDrive/droplet_classification/data_files/yolov5_weights_cell_38_best.pt --img 544 --conf-thres 0.6 --source runs/cropped_drops --hide-labels --hide-conf\n"
      ],
      "metadata": {
        "id": "Tgukw7FQNGW6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.3 Construct Poisson Curve for multiple lambdas: Figure ework"
      ],
      "metadata": {
        "id": "xotzkQrpNS8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prs = []\n",
        "# lambdas = [1,3,6,9]\n",
        "# colors = [\"r\",\"g\",\"b\",\"black\",]\n",
        "# K = list(range(0,21,1))\n",
        "\n",
        "\n",
        "# for lam,c in zip(lambdas,colors):\n",
        "#   Pr = []\n",
        "#   for k in K:\n",
        "#     Pr.append((lam**k)*math.exp(-1*lam)/math.factorial(k))\n",
        "\n",
        "#   plt.plot(K,Pr, markersize=3.5,marker='o', color=c, label=\"\\u03BB = \" + str(lam))\n",
        "\n",
        "\n",
        "# plt.xticks([0,5,10,15,20],[\"0\",\"5\",\"10\",\"15\",\"20\"])\n",
        "# plt.yticks([0.0,0.1,0.2,0.3,0.4],[\"0.0\",\"0.1\",\"0.2\",\"0.2\",\"0.3\",\"0.4\"])\n",
        "# plt.xlabel(\"k\", fontsize=30, fontname=\"Arial\")\n",
        "# plt.ylabel(\"$p_{k}$\", fontsize=30, fontname=\"Arial\")\n",
        "# plt.tick_params(axis='both', which='major', labelsize=25)\n",
        "\n",
        "# plt.legend(fontsize=20)\n",
        "# # plt.subplots_adjust(right=0.1)\n",
        "# plt.savefig(\"/poisson_distribution.png\",dpi=500,bbox_inches='tight')\n",
        "# files.download(\"/poisson_distribution.png\")"
      ],
      "metadata": {
        "id": "xel9P77XNWRt"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}